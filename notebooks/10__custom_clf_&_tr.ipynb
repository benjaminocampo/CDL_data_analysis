{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom transformer CustomScaler is defined for z-score scaling (standardizing) of data. Since scaling doesnâ€™t require learning any parameters from the data, fit method just returns self. The transform method applies the z-score scaling formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return (X - np.mean(X)) / np.std(X)  # simple z-score scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, `OutlierRemoval` is a transformer that removes outliers based on the Interquartile Range (IQR) and `FeatureInteraction` creates interaction terms between features. These are examples of custom transformations that might be useful in pre-processing steps of a machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class OutlierRemoval(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.median = np.median(X, axis=0)\n",
    "        self.iqr = np.percentile(X, 75, axis=0) - np.percentile(X, 25, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        lower_bound = self.median - self.factor * self.iqr\n",
    "        upper_bound = self.median + self.factor * self.iqr\n",
    "        return X[((X >= lower_bound) & (X <= upper_bound)).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here two custom classifiers are defined - `MajorityClassClassifier`, which always predicts the majority class from the training data, and `ThresholdClassifier`, which makes predictions based on a threshold on a particular feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.stats import mode\n",
    "\n",
    "class MajorityClassClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        self.majority_class = mode(y)[0][0]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self.majority_class] * len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, threshold=0.5, feature_index=0):\n",
    "        self.threshold = threshold\n",
    "        self.feature_index = feature_index\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self  # nothing to fit\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (X[:, self.feature_index] > self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class CustomRandomClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Generate random predictions\n",
    "        random_preds = np.random.choice([0, 1], size=len(X), p=[1-self.p, self.p])\n",
    "        return random_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional classifiers like CustomRandomClassifier which randomly predicts classes, HybridClassifier which averages predictions from a Random Forest and an XGBoost model, and SklearnTFHybrid which averages predictions from a Random Forest and a simple Pytorch neural network are also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "class HybridClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, sklearn_classifier=RandomForestClassifier(), xgb_classifier=xgb.XGBClassifier()):\n",
    "        self.sklearn_classifier = sklearn_classifier\n",
    "        self.xgb_classifier = xgb_classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.sklearn_classifier.fit(X, y)\n",
    "        self.xgb_classifier.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        sklearn_preds = self.sklearn_classifier.predict(X)\n",
    "        xgb_preds = self.xgb_classifier.predict(X)\n",
    "        final_preds = (sklearn_preds + xgb_preds) / 2  # Averaging predictions\n",
    "        return final_preds.round().astype(int)  # Round to nearest integer to get class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)  # Assuming 4 features as input\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class SklearnTorchHybrid(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, sklearn_classifier=RandomForestClassifier()):\n",
    "        self.sklearn_classifier = sklearn_classifier\n",
    "        self.torch_model = SimpleNN()\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer = optim.Adam(self.torch_model.parameters(), lr=0.001)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.sklearn_classifier.fit(X, y)\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        for epoch in range(10):  # Assuming 10 epochs\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.torch_model(X_tensor)\n",
    "            loss = self.criterion(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        sklearn_preds = self.sklearn_classifier.predict(X)\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            torch_preds = (self.torch_model(X_tensor) > 0.5).numpy().astype(int).flatten()\n",
    "        final_preds = (sklearn_preds + torch_preds) / 2  # Averaging predictions\n",
    "        return final_preds.round().astype(int)  # Round to nearest integer to get class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scikit-learn pipeline is created combining the CustomScaler transformer and HybridClassifier. This pipeline is then fitted on the training data and evaluated on the test data, showcasing how custom transformers and classifiers can be integrated into scikit-learn pipelines for streamlined model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# For simplicity, convert to a binary classification problem\n",
    "y_binary = (y == 0).astype(int)  # 1 if setosa, 0 otherwise\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assume CustomScaler, ThresholdClassifier, and HybridClassifier are defined as before\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', CustomScaler()),\n",
    "    ('classifier', HybridClassifier(\n",
    "        sklearn_classifier=RandomForestClassifier(random_state=42),\n",
    "        xgb_classifier=xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a261fe3232d26f5c8a3b17afd155c889a6f52aad30d4dff29769029555a05e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('phd-corpora')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
